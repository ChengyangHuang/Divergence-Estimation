# Divergence Estimation Review

## Table of Contents

- [Literatures](#Literatures)
    - [Divergence](#Divergence)
    - [k-NN-based Methods](#k-NN-based-Methods)
    - [KDE-based Methods](#KDE-based-Methods)
    
## Literatures

### Divergence
- **Renyi Divergence and Kullback-Leibler Divergence**  
Tim van Erven and Peter Harremoës. _(IEEE Transactions on Information Theory 2014)_  
[`#Renyi`]() [`#KL`]()  
[[paper]](https://arxiv.org/abs/1202.3758)

- **On measures of entropy and information**  
Alfréd Rényi. _(Berkeley Symposium on Mathematical Statistics and Probability 1961)_  
[`#Renyi`]() [`#KL`]()  
[[paper]](https://digitalassets.lib.berkeley.edu/math/ucb/text/math_s4_v1_article-27.pdf)

### k-NN-based Methods

- **Ensemble estimation of multivariate f-divergence**  
Kevin R. Moon and Alfred O. Hero. _(IEEE International Symposium on Information Theory 2014)_   
[`#knn`]() [`#ensemble`]() [`#f-divergence`]()  
[[paper]](https://arxiv.org/abs/1404.6230)

- **Nonparametric Divergence Estimation with Applications to Machine Learning on Distributions**  
Póczos Barnabás, Liang Xiong, and Jeff Schneider. _(UAI 2011)_  
[`#knn`]()  [`#Renyi`]() [`#L2`]()  
[[paper]](https://arxiv.org/abs/1202.3758) [[code]](https://github.com/djsutherland/np-divs) 


### KDE-based Methods
- **Ensemble estimation of information divergence**   
Kevin R. Moon, Kumar Sricharan, Kristjan Greenewald, and Alfred O. Hero. _(Entropy 2018)_   
[`#kde`]()  [`#ensemble`]()   
[[paper]](https://www.mdpi.com/1099-4300/20/8/560)  
